# Task-1

# Introduction

Another method to collect the data from users is through web scrapping.

Suppose you want some information from a website? Let’s say a paragraph on COVID-19! What would you do? Well, most people will copy and paste the information from Wikipedia to your own file. 
But what if you want to get large amounts of information from a website as quickly as possible? Such as large amounts of data from a website to train a Machine Learning algorithm? In such a situation, copying and pasting will not work! And that’s when you’ll need to use Web Scraping. 

Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data. 

# Important Points

**I have attached the web scraping tools. [Amazon Review](/May-August-Contributions/Priyansh_Singh/Task1/Method-2/Amazon-Product-Reviews.ipynb) is sample code to scrap data. We can implement the same for collecting the data for COVID-19 datasets from various website.**

[CODE](/May-August-Contributions/Priyansh_Singh/Task1/Method-2/Data_Collection.ipynb)

